# CDS-SPEECH-EMOTION-RECOGNITION

Computational Data Science Final Project

One method is to simulate voice emotion recognition using convolutional neural networks (CNNs). CNNs are a subclass of deep learning neural networks that are particularly effective at evaluating data having a grid-like architecture, such as spectrograms of audio signals or picture data. CNNs may be used to extract pertinent information from an utterance's spectrogram, such as the shape and distribution of different frequencies, for speech emotion identication. These features can then be fed into a classiffication model to predict the emotional state conveyed in the utterance. CNNs have been shown to be effective for speech emotion recognition, achieving high levels of accuracy in classifying different emotional states. By leveraging the power of deep learning, CNN-based models can learn to recognize complex patterns in the acoustic features of speech, making them a valuable tool for understanding human emotions in speech.
We successfully predicted the test data set with accuracy of 0.57.

Watch this video for an overview of the project - 
https://www.youtube.com/watch?v=_TPl0hoDlY0

The dataset is obtained from Kaggle - 
https://www.kaggle.com/datasets/dmitrybabko/speech-emotion-recognition-en

